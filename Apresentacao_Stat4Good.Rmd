---
title: "Introdução a Estimação e Modelagem no R com o Uso da Distribuição Birnbaum-Saunders"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introdução

<p style="text-align: justify;">
Foi desenvolvido no artigo "A new family of life distributions" por 
Birnbaum e Saunders a distribuição que ora apresento. A mesma modela o 
tempo de vida de materiais
e equipamentos sujeitos a cargas dinâmicas através de modelos de dano 
acumulado e tem sido amplamente utilizada na área de engenharia, na 
indústria, em negócios, na análise de confiabilidade, na análise de 
sobrevivência, em ciências ambientais e ciências médicas e em diversas 
outras áreas, pois possui propriedades
interessantes e uma relação próxima com a distribuição normal, o que a 
torna, do ponto de vista de aplicação, uma alternativa mais atraente 
para as bem conhecidas distribuições Weibull, log-logística, 
log-normal, gama e modelos inversos Gaussianos.
</p>

```{r}
#Função distribuição acumulada da Birnbaum-Saunders com parâmetros de forma, alpha, e de escala beta.
#Shape=alpha, scala=beta
acbs<-function(t,alpha,beta){
  ff<-pnorm((1/alpha)*(sqrt(t/beta)-sqrt(beta/t)))
  return(ff)
}

#Note que com a mudança de alpha, mantendo beta fixo, há uma alteração na assimetria do gráfico
t=seq(0,3,by=0.01)
plot(t,acbs(t,0.1,1),main='T ~ Birnbaum-Saunders(shape, scale=1)',ylab='F(T<=t)',type='l')
lines(t,acbs(t,0.3,1),col=2,lty=2, lwd=1)
lines(t,acbs(t,0.5,1),col=3,lty=3, lwd=2)
lines(t,acbs(t,0.75,1),col=4,lty=4, lwd=3)
lines(t,acbs(t,1,1),col=5,lty=5, lwd=3)
lines(t,acbs(t,1.5,1),col=6,lty=6, lwd=2)
legend(2.3, 0.55, c("BS(t,0.1,1)","BS(t,0.3,1)","BS(t,0.5,1)","BS(t,0.75,1)","BS(t,1,1)","BS(t,1.5,1)"), fill=1:6)

```
```{r}
#Função densidade da Birnbaum-Saunders com parâmetros de forma, alpha, e de escala beta.
#Shape=alpha, scala=beta

bs<-function(t,alpha,beta){
  f<-((t+beta)/(2*alpha*sqrt(2*pi*beta)))*(t^(-3/2))*exp((-1/(2*alpha^2))*((t/beta)+(beta/t)-2))
  return(f)
}

alpha=10
beta=2
integrand <- function(t){((t+beta)/(2*alpha*sqrt(2*pi*beta)))*(t^(-3/2))*exp((-1/(2*alpha^2))*((t/beta)+(beta/t)-2))}
integrate(integrand, lower = 0, upper = Inf)
```

```{r}
#Note que com a mudança de alpha, mantendo beta fixo, há uma alteração na assimetria do gráfico
t=seq(0,3,by=0.01)
plot(t,bs(t,0.1,1),main='T ~ Birnbaum-Saunders(shape, scale=1)',ylab='Densidade',type='l')
lines(t,bs(t,0.3,1),col=2,lty=2, lwd=1)
lines(t,bs(t,0.5,1),col=3,lty=3, lwd=2)
lines(t,bs(t,0.75,1),col=4,lty=4, lwd=3)
lines(t,bs(t,1,1),col=5,lty=5, lwd=3)
lines(t,bs(t,1.5,1),col=6,lty=6, lwd=2)
legend(2.3, 4, c("BS(t,0.1,1)","BS(t,0.3,1)","BS(t,0.5,1)","BS(t,0.75,1)","BS(t,1,1)","BS(t,1.5,1)"), fill=1:6)

#Enquanto que ao manter alpha fixo e mudar o beta há uma mudança na média e na variança da variável aleatória
#Com o aumento de beta há um aumento da média e da variança
t=seq(0.2,3.5,by=0.01)
plot(t,acbs(t,0.1,0.5),main='T ~ Birnbaum-Saunders(shape=0.1, scale)',ylab='F(T<=t)',type='l')
lines(t,acbs(t,0.1,0.75),col=2,lty=2, lwd=1)
lines(t,acbs(t,0.1,1),col=3,lty=3, lwd=2)
lines(t,acbs(t,0.1,1.5),col=4,lty=4, lwd=3)
lines(t,acbs(t,0.1,2),col=5,lty=5, lwd=3)
lines(t,acbs(t,0.1,2.5),col=6,lty=6, lwd=2)
legend(2.55, 0.55, c("BS(t,0.1,0.5)","BS(t,0.1,0.75)","BS(t,0.1,1)","BS(t,0.1,1.5)","BS(t,0.1,2)","BS(t,0.1,2.5)"), fill=1:6)

#Enquanto que ao manter alpha fixo e mudar o beta há uma mudança na média e na variança da variável aleatória
#Com o aumento de beta há um aumento da média e da variança
t=seq(0,3,by=0.01)
plot(t,bs(t,0.1,0.5),main='T ~ Birnbaum-Saunders(shape=0.1, scale)',ylab='Densidade',type='l')
lines(t,bs(t,0.1,0.75),col=2,lty=2, lwd=1)
lines(t,bs(t,0.1,1),col=3,lty=3, lwd=2)
lines(t,bs(t,0.1,1.5),col=4,lty=4, lwd=3)
lines(t,bs(t,0.1,2),col=5,lty=5, lwd=3)
lines(t,bs(t,0.1,2.5),col=6,lty=6, lwd=2)
legend(2.2, 8, c("BS(t,0.1,0.5)","BS(t,0.1,0.75)","BS(t,0.1,1)","BS(t,0.1,1.5)","BS(t,0.1,2)","BS(t,0.1,2.5)"), fill=1:6)

```

```{r}
########################################
#Usando o plot3d
require(rgl) # Para fazer os gráficos com rotação
require(colorRamps) # Para usar a palleta de cor do matlab
require(plot3D)
require(plot3Drgl)
require(rglwidget)
require(webshot)

alpha=2
beta=1
n=1000
set.seed(355)
z1<-rnorm(1000,0,1)
dados<-beta*((alpha*z1/2)+sqrt((alpha*z1/2)^2+1))^2

alpha= seq(1.5, 2.5,l=100)
beta=seq(0.5,1.5,l=100)

# A função de verossimilhança para fazer o gráfico:
f<-function(alpha,beta){
  t=dados
  sum(log(t+beta))-n*log(2*alpha)-(n/2)*(log(2*pi*beta))-(3/2)*sum(log(t))-((1/(2*alpha^2))*sum((t/beta)+(beta/t)-2))
}

f <- Vectorize(f)

z <- outer(alpha,beta, f)
#open3d()
#bg3d("white")
#material3d(col = "black")
# persp3d(f,xlim=alpha, ylim=beta, contour=TRUE, col = matlab.like,
#         xlab = "Shape", ylab = "Scale", zlab = "Loglik")
# contour(x=alpha,y=beta,z=z,levels = seq(-1805,-2150,length.out = 50))
# points(x=c(2,1),pch=19)
#plotrgl()
#rglwidget()
persp3D(x=alpha, y=beta, z=z, contour=TRUE, facets=TRUE, curtain=F, phi=30,theta=0)
hist3D(x=alpha, y=beta, z=z, contour=TRUE, facets=TRUE, curtain=F, phi=-30,theta=30)
contour(x=alpha, y=beta, z=z,levels = pretty(c(-1780,-2000),20))
points(x=c(2,1),pch=19)
#plotrgl()
########################################
```

```{r}

```

##Simulação de Monte Carlo

O método de Monte Carlo é um método de simulação estatística que utiliza sequencias de números aleatórios para desenvolver simulações. Em outras palavras, é visto como método numérico universal para resolver problemas por meio de amostragem aleatória.

##Possíveis problemas na estimação dos parâmetros

Alguns problemas que tive na implementação da verossimilhança e que merecem destaque:

Veja que apesar de `0.3-0.1=0.2` o R diz que isso não é verdade. Isso ocorre porque nesta diferença o R arredonda o resultado, veja abaixo que se aumentamos o número de dígitos a saída é um número próximo mas diferente de 2.

```{r}

0.3-0.1==0.2
isTRUE(0.3-0.1==0.2)

print(0.3-0.1,digits=17)


```

Outro problema possível é aparecer números muito grandes na simulação de forma que o R entende que o mesmo é infinito e para a simulação. Veja o menor número positívo e o maior número que a maquina pode representar:

```{r}
.Machine
```

Para contornar esse problema, podemos fazer o seguinte truque:

Na definição da função log de verossimilhança mude alpha e beta para exp(lalpha) e exp(lbeta), respectivamente, onde lalpha=log(alpha) e lbeta=log(beta). Ao fazer esta mudança não altera-se em nada a função pois a substituição usa exp(log(alpha))=alpha e exp(log(beta))=beta, isso é um macete para o R não ter que calcular log de números maiores que o maior valor possível (~exp(709)).

Outra forma de resolver, caso o método de otimização funcione, mas aparece alguns valores NA, é manter alpha e beta e acrescentar na função optim o comando abaixo: 

`1-suppressWarnings(optim(start,fn=Loglik,method="BFGS",hessian=T)$par)`
Neste caso escondemos os avisos. Os mesmos continuarão lá, porém ocultos:

Outra forma é caso na simulação apareça números negativos no argumento do log, podemos acrescentar o código:

`if (any(c(t, beta, alpha, pi) < 0)) return(NA)`

Vejamos a estimação de alpha e beta usando uma simulação de Monte Carlo e as funções optim, nlimb e uma função do pacote...

```{r}
##############################################################################
###                                                                        ###
##           Geração de valores e estimação de parâmetros                   ##
###                            BS(alpha,beta)                              ###  
##                                                                          ##
##############################################################################

#geração de valores de uma distribuição Birnbaum-Saunders(alpha,beta)

n<-100

#Gerando uma variável aleatória t com distribuição Birnbaum-Saunders(alpha,beta)
alpha=1
beta=2
truevalue=c(alpha,beta)
#Note que teremos N amostras de tamanho 100 distintas, portanto t
#deve estar dentro do loop do Monte Carlo, alpha e beta deve estar fora do
#Loop pois os mesmos são fixos para todas as amostras.
N=1000
 m=matrix(nrow=N,ncol=2)
m1=matrix(nrow=N,ncol=2)
m2=matrix(nrow=N,ncol=2)
m3=matrix(nrow=N,ncol=2)
for(i in 1:N){
  z<-rnorm(n,0,1)
  #Gerando uma variável aleatória t com distribuição Birnbaum-Saunders(alpha,beta)
  t<-cbind(beta*((alpha*z/2)+sqrt((alpha*z/2)^2+1))^2)
  #Verossimilhança
  Loglik<-function(par,dados){
    lalpha=par[1]
    lbeta=par[2]
    t<-dados
    ll<-sum(log(t+exp(lbeta)))-n*log(2*exp(lalpha))-(n/2)*(log(2*pi*exp(lbeta)))-(3/2)*sum(log(t))-((1/(2*exp(lalpha)^2))*sum((t/exp(lbeta))+(exp(lbeta)/t)-2))
    return(-ll)
  }

  #Utilizando a verossimilhança e a função optim para estimar os parâmetros alpha e beta que deram
  #origem as observações t observadas. Note que foi utilizado o log dos valores de chutes iniciais
  
  lalpha_0=log(2)
  lbeta_0=log(2)
  start=c(lalpha_0,lbeta_0)
  
  m[i,]=exp(optim(start,fn=Loglik,method="BFGS",dados=t,hessian=T)$par)
  m1[i,]=exp(nlminb(start,Loglik,dados=t)$par)
  

}

#Calculating the average of each column of the array of parameters m
mest=colMeans(m)
mest1=colMeans(m1)
#mest2=colMeans(m2)

#calculating the standard deviation of each column of the array of parameters m
dest=apply(m,2,sd)
dest1=apply(m1,2,sd)
#dest2=apply(m2,2,sd)

#root mean square error in the calculation of each column of the array of parameters m in relation to the true value of the parameter
eqm=function(x,poisson_opt){ 
k=length(x)
sqrt(sum(((x-poisson_opt)^2))/k)}

eqm1=function(x,poisson_nlm){ 
k=length(x)
sqrt(sum(((x-poisson_nlm)^2))/k)}

eqm2=function(x,poisson_NR){ 
  k=length(x)
  sqrt(sum(((x-poisson_NR)^2))/k)}

#Estimated mean squared error of each parameter 
eqmest=c(eqm(x=m[,1],poisson_opt=truevalue[1]),
         eqm(x=m[,2],poisson_opt=truevalue[2]))

#Estimated mean squared error of each parameter
eqmest1=c(eqm1(x=m1[,1],poisson_nlm=truevalue[1]),
          eqm1(x=m1[,2],poisson_nlm=truevalue[2]))

#Estimated mean squared error of each parameter
# eqmest2=c(eqm2(x=m2[,1],poisson_NR=truevalue[1]),
#           eqm2(x=m2[,2],poisson_NR=truevalue[2]))



# Table with the true values of the parameters and the average
# Standard deviation and mean square error of the estimated parameters
tab=data.frame(truevalue,mean=mest,sd=dest,eqm=eqmest)
tab1=data.frame(truevalue,mean=mest1,sd=dest1,eqm=eqmest1)
#tab2=data.frame(truevalue,mean=mest2,sd=dest2,eqm=eqmest2)

tab
tab1
#tab2


par(mfrow=c(2,4))
hist(m[,1],prob=T);
rug(m[,1])
curve(expr = dnorm(x,mean=mean(m[,1]),sd=sd(m[,1])),add=T, col="red")
hist(m[,2],prob=T);
rug(m[,2])
curve(expr = dnorm(x,mean=mean(m[,2]),sd=sd(m[,2])),add=T, col="red")
hist(m1[,1],prob=T);
rug(m1[,1])
curve(expr = dnorm(x,mean=mean(m1[,1]),sd=sd(m1[,1])),add=T, col="red")
hist(m1[,2],prob=T);
rug(m1[,2])
curve(expr = dnorm(x,mean=mean(m1[,2]),sd=sd(m1[,2])),add=T, col="red")
# hist(m2[,1],prob=T);
# curve(expr = dnorm(x,mean=mean(m2[,1]),sd=sd(m2[,1])),add=T, col="red")
# hist(m2[,2],prob=T);
# curve(expr = dnorm(x,mean=mean(m2[,2]),sd=sd(m2[,2])),add=T, col="red")

```

```{r}

```



## GitHub Documents

This is an R Markdown format used for publishing markdown documents to GitHub. When you click the **Knit** button all R code chunks are run and a markdown file (.md) suitable for publishing to GitHub is generated.

## Including Code

QUero mostrar ...

```{r}
.Machine[c('double.eps','sizeof.pointer')]

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.




